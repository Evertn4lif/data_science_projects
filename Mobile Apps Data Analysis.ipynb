{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Attributes and Genres Appeal to the Most users in the Free to use app market\n",
    "\n",
    "\n",
    "## This project is going to be focussing on the mobile phone app market specifically that of apps downloaded on the Apple Store and the Google Play Store. \n",
    "\n",
    "The project that i am about to complete is going to be looking at data that we have been able to get from both the IOS and Google Play store platforms. We are going to clean the data so that any missing data is erased, duplicate data is retrived and removed and data that doesnt conform with what we need is also not used so that the analysis that i complete is as fair and rational as possible. \n",
    "\n",
    "The data that i have used for this project has been sourced from:\n",
    "- Google play store (https://www.kaggle.com/lava18/google-play-store-apps)\n",
    "- Apple Store IOS (https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "opened_file = open('AppleStore.csv', encoding=\"utf8\")\n",
    "opened_file2 = open('googleplaystore.csv', encoding=\"utf8\")\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "read_file2 = reader(opened_file2)\n",
    "a = list(read_file)\n",
    "g = list(read_file2)\n",
    "apple_data = a[1:]\n",
    "google_data=g[1:]\n",
    "\n",
    "apple_header = a[0]\n",
    "google_header = g[0]\n",
    "print(len(google_header))\n",
    "print(len(apple_header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and Exploring the Data\n",
    "\n",
    "__Google Play Store Columns__  \n",
    "App, Category, Rating, Reviews, Size, Installs, Type, Price, Content Rating, Genres, Last Updated, Current Ver Android Ver\n",
    "\n",
    "__Apple Store IOS Columns__\n",
    "id, track_name, size_bytes, currency, price, rating_count_tot, rating_count_ver, user_rating, user_rating_ver, ver cont_rating\n",
    "prime_genre, sup_devices.num, ipadSc_urls.num, lang.num, vpp_lic\n",
    "\n",
    "As we can see with the above code we have been apple to sperate the column names for each of the data sets so that we can make sure that we are aware of the meaning of all of the columns. This further helps us clean the data as it has now become apparent that some of the columns are not sueful for the task that we have at hand. \n",
    "\n",
    "I have identified the columns applicable for the Google Play store as being: \n",
    "App, Catergory, Rating, Reviews, Installs, Content Rating. Genre As the columns in the Google Play Store data that most corralate to what we are looking to acheive. This takes us from 13 different columns of data down to 7\n",
    "\n",
    "I have identified the columns applicable for the ApplePlay store as being: \n",
    "track_name, rating_count_tot, user_rating, prime_genre, lang.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite â€“ FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "explore_data(apple_data,0,3,True)\n",
    "explore_data(google_data,0,3,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Wrong Data\n",
    "\n",
    "Now that this peice of data has been deleted a new data point will occupy this space so to run it twice will ruin the data set that we have ammassed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at the discussion for this data it is said that one of the data points is missing some data, due to the fact we want to only use data that is 100% complete i looked into this and as you can see the data point is only showing 12 different columns attached to it meaning that we are missing one peice of data. Due to this i have deletd this data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])\n",
    "print(len(google_data[10472]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del google_data[10472]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Duplicate Data\n",
    "\n",
    "We are now going to look at both of the stores data sets to determine if there are any data points that have been duplicated. To this we are going to loop through the name column for both of the data sets, which is 'track_name' for the IOS and 'App' for the google play store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicates in the IOS store is 2\n",
      "Number of Duplicates in the Google Play Store store is 1181\n"
     ]
    }
   ],
   "source": [
    "apple_single = []\n",
    "apple_dup = []\n",
    "for row in apple_data:\n",
    "    name = row[1]\n",
    "    if name in apple_single:\n",
    "        apple_dup.append(name)\n",
    "    else:\n",
    "        apple_single.append(name)        \n",
    "print(f'Number of Duplicates in the IOS store is {len(apple_dup)}')\n",
    "\n",
    "\n",
    "google_single = []\n",
    "google_dup = []\n",
    "for row in google_data:\n",
    "    name = row[0]\n",
    "    if name in google_single:\n",
    "        google_dup.append(name)\n",
    "    else:\n",
    "        google_single.append(name)        \n",
    "print(f'Number of Duplicates in the Google Play Store store is {len(google_dup)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above, amount of duplicates that are in the dataset in the google play store far surpass that of the IOS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'SOCIAL', '4.1', '78158306', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'August 3, 2018', 'Varies with device', 'Varies with device']\n",
      "['Facebook', 'SOCIAL', '4.1', '78128208', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'August 3, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "for app in google_data:\n",
    "    name = app[0]\n",
    "    if name == 'Facebook':\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a random example of a duplicate app that we have found in our data set. As we do not want to use the app more then once it is prudent that we remove the duplicate data. One of the columns has a different value to the duplicate data whihc is the amount of user reviews. This leads me to belive that the data point wiht a higher number is the more recent data point and thus is the data poiint that we should be keeping for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n",
      "Number of data points: 10840\n",
      "Number of duplicate data points: 1181\n"
     ]
    }
   ],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for row in google_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if name in reviews_max and reviews_max[name]<n_reviews:\n",
    "        reviews_max[name]=n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "print(len(reviews_max))\n",
    "\n",
    "print(f'Number of data points: {len(google_data)}')\n",
    "print(f'Number of duplicate data points: {len(google_dup)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above peice of code we have take the data from the google play store and made a new dictionary out of the data using the apps name as the Key and the number of reviews as the value. As we can also show the remaining duplicate entires have been removed from the data set with 9659 data points remaining in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We start the process of removing the duplicates by initilizing two empty lists\n",
    "- We then loop through each interation of the data and isolate the name and reviews \n",
    "- If the number of reviews is the same as the value of the dictionary then the entire row for that app is added to the clean data\n",
    "- To make sure apps with the same amount of reviews dont get through we make sure to add the name o feach app to a second list and requre that the name not already be in our clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for row in google_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if (n_reviews ==reviews_max[name]) and (name not in already_added):\n",
    "        android_clean.append(row)    \n",
    "        already_added.append(name)\n",
    "len(android_clean) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing non-English Apps\n",
    "\n",
    "We want the app data that we analyise to be of apps that are english language only so it is important that we remove apps from the analysis that are from different countries. We can do this by removing any apps that have letters no represented on a english keyboard. We can use the ord function as we know that the english keyboard only has a representation upto ord 127 so anything after this must mean it is not an english app\n",
    "\n",
    "Due to the fact that emojis are now a very prevalanet addition into the english language it has been decided that because they are outside the range that we are using we will require an app to have more then 3 over 127 valued chars so to include as much relevant data, this is not perfect but it is better the before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_only(app_name):\n",
    "    letter = 0\n",
    "    for a in app_name:\n",
    "        if ord(a)>127:\n",
    "            letter+=1\n",
    "    if letter > 3:\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite â€“ FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9659\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android_clean, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the function that allows us to check if 3 or more letters outside of the english keyoboard, the data of both app stores has been put into the function are two new lists have been created that only hold the clean data of english language apps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9614\n",
      "6183\n"
     ]
    }
   ],
   "source": [
    "andorid_clean_english = []\n",
    "ios_clean_english = []\n",
    "\n",
    "for row in android_clean:\n",
    "    name = row[0]\n",
    "    \n",
    "    english = english_only(name)\n",
    "    if english == True:\n",
    "        andorid_clean_english.append(row) \n",
    "print(len(andorid_clean_english))        \n",
    "    \n",
    "for row in apple_data:\n",
    "    name = row[1]\n",
    "    \n",
    "    english = english_only(name)\n",
    "    if english == True:\n",
    "        ios_clean_english.append(row) \n",
    "print(len(ios_clean_english))         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolating the Free Apps \n",
    "\n",
    "In this step of the data cleaning process we are going to loop through the apps that we have left and then remove any that are not free of charge. To do this i am going to have to isolate the price and use loops and conditionals to filter out the data that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8864\n",
      "3222\n"
     ]
    }
   ],
   "source": [
    "free_clean_android = []\n",
    "free_clean_ios = []\n",
    "\n",
    "\n",
    "for row in andorid_clean_english:\n",
    "    price = row[7]   \n",
    "    if price =='0':\n",
    "        free_clean_android.append(row)\n",
    "print(len(free_clean_android))\n",
    "\n",
    "for row in ios_clean_english:\n",
    "    price = row[4]    \n",
    "    if price =='0.0':\n",
    "        free_clean_ios.append(row)\n",
    "print(len(free_clean_ios))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the non-free apps were removed from the data we were left with 8864 android apps and 3222 IOS apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver'] \n",
      "\n",
      "['Check Vehicle Tax', 'AUTO_AND_VEHICLES', '3.9', '295', '2.7M', '10,000+', 'Free', '0', 'Everyone', 'Auto & Vehicles', 'July 30, 2018', '0.2.1', '4.4 and up'] \n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "print(google_header, '\\n')\n",
    "print(google_data[65], '\\n')\n",
    "print(apple_data[2])\n",
    "print(apple_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned it is finally time that we look at the final cleaned data points and find ways in which to analyise it for the purpose that we originally set out for. \n",
    "From the columns that i have just pulled up it seems to me that the best data points to use for frequency tables would be \n",
    "\n",
    "Google - Category, installs\n",
    "IOS - prime_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset,index):\n",
    "    freq_dict = {}\n",
    "    count = len(dataset)\n",
    "    for row in dataset:\n",
    "        if row[index] in freq_dict:\n",
    "            freq_dict[row[index]]+=1\n",
    "        else:\n",
    "            freq_dict[row[index]]=1\n",
    "    table_percentage = {}        \n",
    "    for genre in freq_dict:\n",
    "        percentage = (freq_dict[genre] /count)*100\n",
    "        table_percentage[genre] = percentage\n",
    "    return table_percentage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_genre_per= freq_table(free_clean_android,1)\n",
    "ios_genre_per = freq_table(free_clean_ios,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY : 18.907942238267147\n",
      "GAME : 9.724729241877256\n",
      "TOOLS : 8.461191335740072\n",
      "BUSINESS : 4.591606498194946\n",
      "LIFESTYLE : 3.9034296028880866\n",
      "PRODUCTIVITY : 3.892148014440433\n",
      "FINANCE : 3.7003610108303246\n",
      "MEDICAL : 3.531137184115524\n",
      "SPORTS : 3.395758122743682\n",
      "PERSONALIZATION : 3.3167870036101084\n",
      "COMMUNICATION : 3.2378158844765346\n",
      "HEALTH_AND_FITNESS : 3.0798736462093865\n",
      "PHOTOGRAPHY : 2.944494584837545\n",
      "NEWS_AND_MAGAZINES : 2.7978339350180503\n",
      "SOCIAL : 2.6624548736462095\n",
      "TRAVEL_AND_LOCAL : 2.33528880866426\n",
      "SHOPPING : 2.2450361010830324\n",
      "BOOKS_AND_REFERENCE : 2.1435018050541514\n",
      "DATING : 1.861462093862816\n",
      "VIDEO_PLAYERS : 1.7937725631768955\n",
      "MAPS_AND_NAVIGATION : 1.3989169675090252\n",
      "FOOD_AND_DRINK : 1.2409747292418771\n",
      "EDUCATION : 1.1620036101083033\n",
      "ENTERTAINMENT : 0.9589350180505415\n",
      "LIBRARIES_AND_DEMO : 0.9363718411552346\n",
      "AUTO_AND_VEHICLES : 0.9250902527075812\n",
      "HOUSE_AND_HOME : 0.8235559566787004\n",
      "WEATHER : 0.8009927797833934\n",
      "EVENTS : 0.7107400722021661\n",
      "PARENTING : 0.6543321299638989\n",
      "ART_AND_DESIGN : 0.6430505415162455\n",
      "COMICS : 0.6204873646209386\n",
      "BEAUTY : 0.5979241877256317\n"
     ]
    }
   ],
   "source": [
    "display_table(free_clean_android,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 58.16263190564867\n",
      "Entertainment : 7.883302296710118\n",
      "Photo & Video : 4.9658597144630665\n",
      "Education : 3.662321539416512\n",
      "Social Networking : 3.2898820608317814\n",
      "Shopping : 2.60707635009311\n",
      "Utilities : 2.5139664804469275\n",
      "Sports : 2.1415270018621975\n",
      "Music : 2.0484171322160147\n",
      "Health & Fitness : 2.0173805090006205\n",
      "Productivity : 1.7380509000620732\n",
      "Lifestyle : 1.5828677839851024\n",
      "News : 1.3345747982619491\n",
      "Travel : 1.2414649286157666\n",
      "Finance : 1.1173184357541899\n",
      "Weather : 0.8690254500310366\n",
      "Food & Drink : 0.8069522036002483\n",
      "Reference : 0.5586592178770949\n",
      "Business : 0.5276225946617008\n",
      "Book : 0.4345127250155183\n",
      "Navigation : 0.186219739292365\n",
      "Medical : 0.186219739292365\n",
      "Catalogs : 0.12414649286157665\n"
     ]
    }
   ],
   "source": [
    "display_table(free_clean_ios,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
